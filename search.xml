<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>TEST</title>
    <url>/2020/03/10/TEST/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>精准推送</title>
    <url>/2020/03/10/%E7%B2%BE%E5%87%86%E6%8E%A8%E9%80%81/</url>
    <content><![CDATA[<p>基于用户感兴趣的物品A，找到和A内容信息相近的物品B</p>
<p>（1）找到物品A的内容信息</p>
<p>（2）找到与内容信息相近的物品B</p>
<p>运用：这种推荐算法多数运用在简单的推荐列表上，当用户看了物品A立刻展示推荐关联的物品B，不需要通过大量计算反馈。但由于其局限性并不能精准推荐出用户所喜欢的内容。<br><img src="/images/cover05.jpg" alt></p>
]]></content>
  </entry>
  <entry>
    <title>邻近算法</title>
    <url>/2020/03/10/%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。<br>kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。</p>
<p>K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN方法虽然从原理上也依赖于极限定理，但在类别决策时，只与极少量的相邻样本有关。由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。<br>KNN算法不仅可以用于分类，还可以用于回归。通过找出一个样本的k个最近邻居，将这些邻居的属性的平均值赋给该样本，就可以得到该样本的属性。更有用的方法是将不同距离的邻居对该样本产生的影响给予不同的权值(weight)，如权值与距离成反比。</p>
]]></content>
      <tags>
        <tag>学习 技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning</title>
    <url>/2020/03/10/Machine-Learning/</url>
    <content><![CDATA[<p>机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。<br>它是人工智能的核心，是使计算机具有智能的根本途径。</p>
<p>机器学习是一门多学科交叉专业，涵盖概率论知识，统计学知识，近似理论知识和复杂算法知识，使用计算机作为工具并致力于真实实时的模拟人类学习方式， 并将现有内容进行知识结构划分来有效提高学习效率。 [1]<br>机器学习有下面几种定义：<br>(1) 机器学习是一门人工智能的科学,该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。<br>(2) 机器学习是对能通过经验自动改进的计算机算法的研究。<br>(3) 机器学习是用数据或以往的经验,以此优化计算机程序的性能标准</p>
<h3 id="决策树-decision-tree-是一种基本的分类与回归方法"><a href="#决策树-decision-tree-是一种基本的分类与回归方法" class="headerlink" title="决策树(decision tree)是一种基本的分类与回归方法"></a>决策树(decision tree)是一种基本的分类与回归方法</h3><p>决策树算法的核心在于决策树的构建，每次选择让整体数据香农熵（描述数据的混乱程度）减小最多的特征，使用其特征值对数据进行划分，每次消耗一个特征，不断迭代分类，直到所有特征消耗完（选择剩下数据中出现次数最多的类别作为这堆数据的类别），或剩下的数据全为同一类别，不必继续划分，至此决策树构建完成，之后我们依照这颗决策树对新进数据进行分类。</p>
<h3 id="结点和模块的概念"><a href="#结点和模块的概念" class="headerlink" title="结点和模块的概念"></a>结点和模块的概念</h3><p> 一个决策树，长方形代表判断模块(decision block)，椭圆形成代表终止模块(terminating block)，表示已经得出结论，可以终止运行。从判断模块引出的左右箭头称作为分支(branch)，它可以达到另一个判断模块或者终止模块。我们还可以这样理解，分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示一个类。如图所示的决策树，长方形和椭圆形都是结点。长方形的结点属于内部结点，椭圆形的结点属于叶结点，从结点引出的左右箭头就是有向边。而最上面的结点就是决策树的根结点(root node)。</p>
<h3 id="使用决策树做预测需要的过程"><a href="#使用决策树做预测需要的过程" class="headerlink" title="使用决策树做预测需要的过程"></a>使用决策树做预测需要的过程</h3><p>收集数据：可以使用任何方法。比如想构建一个相亲系统，我们可以从媒婆那里，或者通过参访相亲对象获取数据。根据他们考虑的因素和最终的选择结果，就可以得到一些供我们利用的数据了。<br>准备数据：收集完的数据，我们要进行整理，将这些所有收集的信息按照一定规则整理出来，并排版，方便我们进行后续处理。<br>分析数据：可以使用任何方法，决策树构造完成之后，我们可以检查决策树图形是否符合预期。<br>训练算法：这个过程也就是构造决策树，同样也可以说是决策树学习，就是构造一个决策树的数据结构。<br>测试算法：使用经验树计算错误率。当错误率达到了可接收范围，这个决策树就可以投放使用了。<br>使用算法：此步骤可以使用适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。</p>
<h3 id="编写代码计算经验熵"><a href="#编写代码计算经验熵" class="headerlink" title="编写代码计算经验熵"></a>编写代码计算经验熵</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line">from math import <span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:创建测试数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-07-20</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def createDataSet():</span><br><span class="line">    dataSet = [[0, 0, 0, 0, <span class="string">'no'</span>],         <span class="comment">#数据集</span></span><br><span class="line">            [0, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [0, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 1, 1, 0, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [1, 1, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 0, 0, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'年龄'</span>, <span class="string">'有工作'</span>, <span class="string">'有自己的房子'</span>, <span class="string">'信贷情况'</span>]        <span class="comment">#分类属性</span></span><br><span class="line">    <span class="built_in">return</span> dataSet, labels                <span class="comment">#返回数据集和分类属性</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:计算给定数据集的经验熵(香农熵)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵(香农熵)</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def calcShannonEnt(dataSet):</span><br><span class="line">    numEntires = len(dataSet)                        <span class="comment">#返回数据集的行数</span></span><br><span class="line">    labelCounts = &#123;&#125;                                <span class="comment">#保存每个标签(Label)出现次数的字典</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:                            <span class="comment">#对每组特征向量进行统计</span></span><br><span class="line">        currentLabel = featVec[-1]                    <span class="comment">#提取标签(Label)信息</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel not <span class="keyword">in</span> labelCounts.keys():    <span class="comment">#如果标签(Label)没有放入统计次数的字典,添加进去</span></span><br><span class="line">            labelCounts[currentLabel] = 0</span><br><span class="line">        labelCounts[currentLabel] += 1                <span class="comment">#Label计数</span></span><br><span class="line">    shannonEnt = 0.0                                <span class="comment">#经验熵(香农熵)</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:                            <span class="comment">#计算香农熵</span></span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numEntires    <span class="comment">#选择该标签(Label)的概率</span></span><br><span class="line">        shannonEnt -= prob * <span class="built_in">log</span>(prob, 2)            <span class="comment">#利用公式计算</span></span><br><span class="line">    <span class="built_in">return</span> shannonEnt                                <span class="comment">#返回经验熵(香农熵)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dataSet, features = createDataSet()</span><br><span class="line">    <span class="built_in">print</span>(dataSet)</span><br><span class="line">    <span class="built_in">print</span>(calcShannonEnt(dataSet))</span><br></pre></td></tr></table></figure>


<h3 id="编写代码计算信息增益"><a href="#编写代码计算信息增益" class="headerlink" title="编写代码计算信息增益"></a>编写代码计算信息增益</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$#</span> -*- coding: UTF-8 -*-</span><br><span class="line">from math import <span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:计算给定数据集的经验熵(香农熵)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵(香农熵)</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-03-29</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def calcShannonEnt(dataSet):</span><br><span class="line">    numEntires = len(dataSet)                        <span class="comment">#返回数据集的行数</span></span><br><span class="line">    labelCounts = &#123;&#125;                                <span class="comment">#保存每个标签(Label)出现次数的字典</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:                            <span class="comment">#对每组特征向量进行统计</span></span><br><span class="line">        currentLabel = featVec[-1]                    <span class="comment">#提取标签(Label)信息</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel not <span class="keyword">in</span> labelCounts.keys():    <span class="comment">#如果标签(Label)没有放入统计次数的字典,添加进去</span></span><br><span class="line">            labelCounts[currentLabel] = 0</span><br><span class="line">        labelCounts[currentLabel] += 1                <span class="comment">#Label计数</span></span><br><span class="line">    shannonEnt = 0.0                                <span class="comment">#经验熵(香农熵)</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:                            <span class="comment">#计算香农熵</span></span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numEntires    <span class="comment">#选择该标签(Label)的概率</span></span><br><span class="line">        shannonEnt -= prob * <span class="built_in">log</span>(prob, 2)            <span class="comment">#利用公式计算</span></span><br><span class="line">    <span class="built_in">return</span> shannonEnt                                <span class="comment">#返回经验熵(香农熵)</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:创建测试数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-07-20</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def createDataSet():</span><br><span class="line">    dataSet = [[0, 0, 0, 0, <span class="string">'no'</span>],                        <span class="comment">#数据集</span></span><br><span class="line">            [0, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [0, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 1, 1, 0, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [1, 1, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 0, 0, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'年龄'</span>, <span class="string">'有工作'</span>, <span class="string">'有自己的房子'</span>, <span class="string">'信贷情况'</span>]        <span class="comment">#分类属性</span></span><br><span class="line">    <span class="built_in">return</span> dataSet, labels                             <span class="comment">#返回数据集和分类属性</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:按照给定特征划分数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 待划分的数据集</span></span><br><span class="line"><span class="string">    axis - 划分数据集的特征</span></span><br><span class="line"><span class="string">    value - 需要返回的特征的值</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-03-30</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def splitDataSet(dataSet, axis, value):</span><br><span class="line">    retDataSet = []                                        <span class="comment">#创建返回的数据集列表</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:                             <span class="comment">#遍历数据集</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:</span><br><span class="line">            reducedFeatVec = featVec[:axis]                <span class="comment">#去掉axis特征</span></span><br><span class="line">            reducedFeatVec.extend(featVec[axis+1:])     <span class="comment">#将符合条件的添加到返回的数据集</span></span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="built_in">return</span> retDataSet                                      <span class="comment">#返回划分后的数据集</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    bestFeature - 信息增益最大的(最优)特征的索引值</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def chooseBestFeatureToSplit(dataSet):</span><br><span class="line">    numFeatures = len(dataSet[0]) - 1                    <span class="comment">#特征数量</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)                 <span class="comment">#计算数据集的香农熵</span></span><br><span class="line">    bestInfoGain = 0.0                                  <span class="comment">#信息增益</span></span><br><span class="line">    bestFeature = -1                                    <span class="comment">#最优特征的索引值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):                         <span class="comment">#遍历所有特征</span></span><br><span class="line">        <span class="comment">#获取dataSet的第i个所有特征</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)                         <span class="comment">#创建set集合&#123;&#125;,元素不可重复</span></span><br><span class="line">        newEntropy = 0.0                                  <span class="comment">#经验条件熵</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:                         <span class="comment">#计算信息增益</span></span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)         <span class="comment">#subDataSet划分后的子集</span></span><br><span class="line">            prob = len(subDataSet) / <span class="built_in">float</span>(len(dataSet))           <span class="comment">#计算子集的概率</span></span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)     <span class="comment">#根据公式计算经验条件熵</span></span><br><span class="line">        infoGain = baseEntropy - newEntropy                     <span class="comment">#信息增益</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"第%d个特征的增益为%.3f"</span> % (i, infoGain))            <span class="comment">#打印每个特征的信息增益</span></span><br><span class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):                             <span class="comment">#计算信息增益</span></span><br><span class="line">            bestInfoGain = infoGain                             <span class="comment">#更新信息增益，找到最大的信息增益</span></span><br><span class="line">            bestFeature = i                                     <span class="comment">#记录信息增益最大的特征的索引值</span></span><br><span class="line">    <span class="built_in">return</span> bestFeature                                             <span class="comment">#返回信息增益最大的特征的索引值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dataSet, features = createDataSet()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"最优特征索引值:"</span> + str(chooseBestFeatureToSplit(dataSet)))</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>科技 技术 学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning</title>
    <url>/2020/03/10/Deep-Learning/</url>
    <content><![CDATA[<p>深度学习(DL, Deep Learning)是机器学习(ML, Machine Learning)领域中一个新的研究方向，它被引入机器学习使其更接近于最初的目标——人工智能(AI, Artificial Intelligence)。<br>深度学习是学习样本数据的内在规律和表示层次，这些学习过程中获得的信息对诸如文字，图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。 深度学习是一个复杂的机器学习算法，在语音和图像识别方面取得的效果，远远超过先前相关技术。<br>深度学习在搜索技术，数据挖掘，机器学习，机器翻译，自然语言处理，多媒体学习，语音，推荐和个性化技术，以及其他相关领域都取得了很多成果。深度学习使机器模仿视听和思考等人类的活动，解决了很多复杂的模式识别难题，使得人工智能相关技术取得了很大进步。</p>
<h2 id="十种深度学习算法要点及代码解析"><a href="#十种深度学习算法要点及代码解析" class="headerlink" title="十种深度学习算法要点及代码解析"></a>十种深度学习算法要点及代码解析</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>Python 代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$#Import</span> Library</span><br><span class="line"><span class="comment">#Import other necessary libraries like pandas, numpy...</span></span><br><span class="line">from sklearn import linear_model</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Load Train and Test datasets</span></span><br><span class="line"><span class="comment">#Identify feature and response variable(s) and values must be numeric and numpy arrays</span></span><br><span class="line">x_train=input_variables_values_training_datasets</span><br><span class="line">y_train=target_variables_values_training_datasets</span><br><span class="line">x_test=input_variables_values_test_datasets</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create linear regression object</span></span><br><span class="line">linear = linear_model.LinearRegression()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">linear.fit(x_train, y_train)</span><br><span class="line">linear.score(x_train, y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Equation coefficient and Intercept</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Coefficient: n'</span>, linear.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Intercept: n'</span>, linear.intercept_)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= linear.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Load Train and Test datasets</span></span><br><span class="line"><span class="comment">#Identify feature and response variable(s) and values must be numeric and numpy arrays</span></span><br><span class="line">x_train &lt;- input_variables_values_training_datasets</span><br><span class="line">y_train &lt;- target_variables_values_training_datasets</span><br><span class="line">x_test &lt;- input_variables_values_test_datasets</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">linear &lt;- lm(y_train ~ ., data = x)</span><br><span class="line">summary(linear)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(linear,x_test)</span><br></pre></td></tr></table></figure>

<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>别被它的名字迷惑了！这是一个分类算法而不是一个回归算法。该算法可根据已知的一系列因变量估计离散数值（比方说二进制数值 0 或 1 ，是或否，真或假）。简单来说，它通过将数据拟合进一个逻辑函数来预估一个事件出现的概率。因此，它也被叫做逻辑回归。因为它预估的是概率，所以它的输出值大小在 0 和 1 之间（正如所预计的一样）。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$#Import</span> Library</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create logistic regression object</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Equation coefficient and Intercept</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Coefficient: n'</span>, model.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Intercept: n'</span>, model.intercept_)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>

<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ x &lt;- cbind(x_train,y_train)</span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">logistic &lt;- glm(y_train ~ ., data = x,family=<span class="string">'binomial'</span>)</span><br><span class="line">summary(logistic)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(logistic,x_test)</span><br></pre></td></tr></table></figure>

<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>这个监督式学习算法通常被用于分类问题。令人惊奇的是，它同时适用于分类变量和连续因变量。在这个算法中，我们将总体分成两个或更多的同类群。这是根据最重要的属性或者自变量来分成尽可能不同的组别。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line"><span class="comment">#Import other necessary libraries like pandas, numpy...</span></span><br><span class="line">from sklearn import tree</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create tree object</span></span><br><span class="line">model = tree.DecisionTreeClassifier(criterion=<span class="string">'gini'</span>)</span><br><span class="line"><span class="comment"># for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini </span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># model = tree.DecisionTreeRegressor() for regression</span></span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>

<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$library</span>(rpart)</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># grow tree</span></span><br><span class="line">fit &lt;- rpart(y_train ~ ., data = x,method=<span class="string">"class"</span>)</span><br><span class="line">summary(fit)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>

<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>这是一种分类方法。在这个算法中，我们将每个数据在N维空间中用点标出（N是你所有的特征总数），每个特征的值是一个坐标的值。</p>
<p>举个例子，如果我们只有身高和头发长度两个特征，我们会在二维空间中标出这两个变量，每个点有两个坐标（这些坐标叫做支持向量）。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn import svm</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (predic</span></span><br><span class="line">tor) and Y (target) <span class="keyword">for</span> training data <span class="built_in">set</span> and x_test(predictor) of test_dataset</span><br><span class="line"><span class="comment"># Create SVM classification object</span></span><br><span class="line">model = svm.svc()</span><br><span class="line"><span class="comment"># there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail.</span></span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$library</span>(e1071)</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Fitting model</span></span><br><span class="line">fit &lt;-svm(y_train ~ ., data = x)</span><br><span class="line">summary(fit)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>


<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p>在预示变量间相互独立的前提下，根据 贝叶斯定理 可以得到朴素贝叶斯这个分类方法。用更简单的话来说，一个朴素贝叶斯分类器假设一个分类的特性与该分类的其它特性不相关。举个例子，如果一个水果又圆又红 ， 并且直径大约是 3 英寸，那么这个水果可能会是苹果。即便这些特性互相依赖 ， 或者依赖于别的特性的存在，朴素贝叶斯分类器还是会假设这些特性分别独立地暗示这个水果是个苹果。</p>
<p>朴素贝叶斯模型易于建造，且对于大型数据集非常有用。虽然简单，但是朴素贝叶斯的表现却超越了非常复杂的分类方法。</p>
<p>贝叶斯定理提供了一种从P(c)、P(x)和P(x|c) 计算后验概率 P(c|x) 的方法。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create SVM classification object model = GaussianNB() # there is other distribution for multinomial classes like Bernoulli Naive Bayes, Refer link</span></span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ library(e1071)</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Fitting model</span></span><br><span class="line">fit &lt;-naiveBayes(y_train ~ ., data = x)</span><br><span class="line">summary(fit)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>


<h3 id="KNN（K-–-最近邻算法）"><a href="#KNN（K-–-最近邻算法）" class="headerlink" title="KNN（K – 最近邻算法）"></a>KNN（K – 最近邻算法）</h3><p>该算法可用于分类问题和回归问题。然而，在业界内，K – 最近邻算法更常用于分类问题。K – 最近邻算法是一个简单的算法。它储存所有的案例，通过周围k个案例中的大多数情况划分新的案例。根据一个距离函数，新案例会被分配到它的 K 个近邻中最普遍的类别中去。</p>
<p>这些距离函数可以是欧式距离、曼哈顿距离、明式距离或者是汉明距离。前三个距离函数用于连续函数，第四个函数（汉明函数）则被用于分类变量。如果 K=1，新案例就直接被分到离其最近的案例所属的类别中。有时候，使用 KNN 建模时，选择 K 的取值是一个挑战。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create KNeighbors classifier object model</span></span><br><span class="line">KNeighborsClassifier(n_neighbors=6)</span><br><span class="line"><span class="comment"># default value for n_neighbors is 5</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ library(knn)</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Fitting model</span></span><br><span class="line">fit &lt;-knn(y_train ~ ., data = x,k=5)</span><br><span class="line">summary(fit)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>

<h3 id="K-均值算法"><a href="#K-均值算法" class="headerlink" title="K 均值算法"></a>K 均值算法</h3><p>K – 均值算法是一种非监督式学习算法，它能解决聚类问题。使用 K – 均值算法来将一个数据归入一定数量的集群（假设有 k 个集群）的过程是简单的。一个集群内的数据点是均匀齐次的，并且异于别的集群。</p>
<p>还记得从墨水渍里找出形状的活动吗？K – 均值算法在某方面类似于这个活动。观察形状，并延伸想象来找出到底有多少种集群或者总体。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (attributes) for training data set and x_test(attributes) of test_dataset</span></span><br><span class="line"><span class="comment"># Create KNeighbors classifier object model</span></span><br><span class="line">k_means = KMeans(n_clusters=3, random_state=0)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>

<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ library(cluster)</span><br><span class="line">fit &lt;- kmeans(X, 3) <span class="comment"># 5 cluster solution</span></span><br></pre></td></tr></table></figure>

<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林是表示决策树总体的一个专有名词。在随机森林算法中，我们有一系列的决策树（因此又名“森林”）。为了根据一个新对象的属性将其分类，每一个决策树有一个分类，称之为这个决策树“投票”给该分类。这个森林选择获得森林里（在所有树中）获得票数最多的分类。</p>
<p>每棵树是像这样种植养成的：</p>
<p>如果训练集的案例数是 N，则从 N 个案例中用重置抽样法随机抽取样本。这个样本将作为“养育”树的训练集。<br>假如有 M 个输入变量，则定义一个数字 m&lt;&lt;M。m 表示，从 M 中随机选中 m 个变量，这 m 个变量中最好的切分会被用来切分该节点。在种植森林的过程中，m 的值保持不变。<br>尽可能大地种植每一棵树，全程不剪枝。</p>
<p>Python</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create Random Forest object</span></span><br><span class="line">model= RandomForestClassifier()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>

<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ library(randomForest)</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Fitting model</span></span><br><span class="line">fit &lt;- randomForest(Species ~ ., x,ntree=500)</span><br><span class="line">summary(fit)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= predict(fit,x_test)</span><br></pre></td></tr></table></figure>

<h3 id="降维算法"><a href="#降维算法" class="headerlink" title="降维算法"></a>降维算法</h3><p>在过去的 4 到 5 年里，在每一个可能的阶段，信息捕捉都呈指数增长。公司、政府机构、研究组织在应对着新资源以外，还捕捉详尽的信息。</p>
<p>举个例子：电子商务公司更详细地捕捉关于顾客的资料：个人信息、网络浏览记录、他们的喜恶、购买记录、反馈以及别的许多信息，比你身边的杂货店售货员更加关注你。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn import decomposition</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have training and test data set as train and test</span></span><br><span class="line"><span class="comment"># Create PCA obeject pca= decomposition.PCA(n_components=k) #default value of k =min(n_sample, n_features)</span></span><br><span class="line"><span class="comment"># For Factor analysis</span></span><br><span class="line"><span class="comment">#fa= decomposition.FactorAnalysis()</span></span><br><span class="line"><span class="comment"># Reduced the dimension of training dataset using PCA</span></span><br><span class="line">train_reduced = pca.fit_transform(train)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Reduced the dimension of test dataset</span></span><br><span class="line">test_reduced = pca.transform(<span class="built_in">test</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#For more detail on this, please refer  this link.</span></span><br></pre></td></tr></table></figure>

<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ library(stats)</span><br><span class="line">pca &lt;- princomp(train, cor = TRUE)</span><br><span class="line">train_reduced  &lt;- predict(pca,train)</span><br><span class="line">test_reduced  &lt;- predict(pca,<span class="built_in">test</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Gradient-Boosting-和-AdaBoost-算法"><a href="#Gradient-Boosting-和-AdaBoost-算法" class="headerlink" title="Gradient Boosting 和 AdaBoost 算法"></a>Gradient Boosting 和 AdaBoost 算法</h3><p>当我们要处理很多数据来做一个有高预测能力的预测时，我们会用到 GBM 和 AdaBoost 这两种 boosting 算法。boosting 算法是一种集成学习算法。它结合了建立在多个基础估计值基础上的预测结果，来增进单个估计值的可靠程度。这些 boosting 算法通常在数据科学比赛如 Kaggl、AV Hackathon、CrowdAnalytix 中很有效。</p>
<p>Python代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment">#Import Library</span></span><br><span class="line">from sklearn.ensemble import GradientBoostingClassifier</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create Gradient Boosting Classifier object</span></span><br><span class="line">model= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>

<p>R代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ library(caret)</span><br><span class="line">x &lt;- cbind(x_train,y_train)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Fitting model</span></span><br><span class="line">fitControl &lt;- trainControl( method = <span class="string">"repeatedcv"</span>, number = 4, repeats = 4)</span><br><span class="line">fit &lt;- train(y ~ ., data = x, method = <span class="string">"gbm"</span>, trControl = fitControl,verbose = FALSE)</span><br><span class="line">predicted= predict(fit,x_test,<span class="built_in">type</span>= <span class="string">"prob"</span>)[,2]</span><br></pre></td></tr></table></figure>
<p>GradientBoostingClassifier 和随机森林是两种不同的 boosting 树分类器。</p>
<p>如果你想要掌握机器学习，那就立刻开始吧。做做练习，理性地认识整个过程，应用这些代码，并感受乐趣吧！</p>
]]></content>
      <tags>
        <tag>学习 技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Vue.js</title>
    <url>/2020/03/10/Vue-js/</url>
    <content><![CDATA[<p>Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。</p>
<h3 id="动态设置页面标题"><a href="#动态设置页面标题" class="headerlink" title="动态设置页面标题"></a>动态设置页面标题</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ import VueRouter from <span class="string">'vue-router'</span>;</span><br><span class="line">...</span><br><span class="line"> </span><br><span class="line">//加载 vue-router 插件</span><br><span class="line">Vue.use(VueRouter);</span><br><span class="line"> </span><br><span class="line">/*定义路由匹配表*/</span><br><span class="line">const Routers = [&#123;</span><br><span class="line"> path: <span class="string">'/index'</span>,</span><br><span class="line"> component: (resolve) =&gt; require([<span class="string">'./router/views/index.vue'</span>], resolve),</span><br><span class="line"> meta: &#123;</span><br><span class="line">  title: <span class="string">'首页'</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;,</span><br><span class="line"> //一次性加载</span><br><span class="line"> // &#123;</span><br><span class="line"> //  path: <span class="string">'/index'</span>,</span><br><span class="line"> //  component: require(<span class="string">'./router/views/index.vue'</span>)</span><br><span class="line"> // &#125;,</span><br><span class="line"> &#123;</span><br><span class="line">  path: <span class="string">'/about'</span>,</span><br><span class="line">  component: (resolve) =&gt; require([<span class="string">'./router/views/about.vue'</span>], resolve),</span><br><span class="line">  meta: &#123;</span><br><span class="line">   title: <span class="string">'关于'</span></span><br><span class="line">  &#125;</span><br><span class="line"> &#125;,</span><br><span class="line"> &#123;</span><br><span class="line">  path: <span class="string">'/article/:id'</span>,</span><br><span class="line">  component: (resolve) =&gt; require([<span class="string">'./router/views/article.vue'</span>], resolve)</span><br><span class="line"> &#125;</span><br><span class="line"> ,</span><br><span class="line"> &#123;//当访问的页面不存在时，重定向到首页</span><br><span class="line">  path: <span class="string">'*'</span>,</span><br><span class="line">  redirect: <span class="string">'/index'</span></span><br><span class="line"> &#125;</span><br><span class="line">]</span><br><span class="line">//路由配置</span><br><span class="line">const RouterConfig = &#123;</span><br><span class="line"> //使用 HTML5 的 History 路由模式</span><br><span class="line"> mode: <span class="string">'history'</span>,</span><br><span class="line"> routes: Routers</span><br><span class="line">&#125;;</span><br><span class="line">//路由实例</span><br><span class="line">const router = new VueRouter(RouterConfig);</span><br><span class="line">//动态设置页面标题</span><br><span class="line">router.beforeEach((to, from, next) =&gt; &#123;</span><br><span class="line"> window.document.title = to.meta.title;</span><br><span class="line"> next();</span><br><span class="line">&#125;)</span><br><span class="line">new Vue(&#123;</span><br><span class="line"> el: <span class="string">'#app'</span>,</span><br><span class="line"> router: router,</span><br><span class="line"> render: h =&gt; h(Hello)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<h3 id="长页面跳转自动返回顶端"><a href="#长页面跳转自动返回顶端" class="headerlink" title="长页面跳转自动返回顶端"></a>长页面跳转自动返回顶端</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ router.afterEach((to, from, next) =&gt; &#123;</span><br><span class="line"> window.scrollTo(0, 0);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>


<h3 id="router-afterEach-to-from-next-gt"><a href="#router-afterEach-to-from-next-gt" class="headerlink" title="router.afterEach((to, from, next) =&gt; {"></a>router.afterEach((to, from, next) =&gt; {</h3><p> window.scrollTo(0, 0);<br>});</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ router.beforeEach((to, from, next) =&gt; &#123;</span><br><span class="line"> <span class="keyword">if</span> (window.localStorage.getItem(<span class="string">'token'</span>)) &#123;</span><br><span class="line">  next();</span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  next(<span class="string">'/login'</span>);</span><br><span class="line"> &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>next() 入参，如果是 false，会不导航；如果为路径，则会导航到指定路径下的页面。</p>
]]></content>
      <tags>
        <tag>技术  代码  学习</tag>
      </tags>
  </entry>
  <entry>
    <title>树莓派</title>
    <url>/2020/03/10/%E6%A0%91%E8%8E%93%E6%B4%BE/</url>
    <content><![CDATA[<p>树莓派由注册于英国的慈善组织“Raspberry Pi 基金会”开发，Eben·Upton/埃·厄普顿为项目带头人。2012年3月，英国剑桥大学埃本·阿普顿（Eben Epton）正式发售世界上最小的台式机，又称卡片式电脑，外形只有信用卡大小，却具有电脑的所有基本功能，这就是Raspberry Pi电脑板，中文译名”树莓派”。这一基金会以提升学校计算机科学及相关学科的教育，让计算机变得有趣为宗旨。基金会期望这 一款电脑无论是在发展中国家还是在发达国家，会有更多的其它应用不断被开发出来，并应用到更多领域。在2006年树莓派早期概念是基于Atmel的 ATmega644单片机，首批上市的10000“台”树莓派的“板子”，由中国台湾和大陆厂家制造。<br>它是一款基于ARM的微型电脑主板，以SD/MicroSD卡为内存硬盘，卡片主板周围有1/2/4个USB接口和一个10/100 以太网接口（A型没有网口），可连接键盘、鼠标和网线，同时拥有视频模拟信号的电视输出接口和HDMI高清视频输出接口，以上部件全部整合在一张仅比信用卡稍大的主板上，具备所有PC的基本功能只需接通电视机和键盘，就能执行如电子表格、文字处理、玩游戏、播放高清视频等诸多功能。 Raspberry Pi B款只提供电脑板，无内存、电源、键盘、机箱或连线。<br>树莓派的生产是通过有生产许可的三家公司Element 14/Premier Farnell、RS Components及Egoman。这三家公司都在网上出售树莓派。你可以在诸如京东、淘宝等国内网站购买到你所想要的树莓派。<br>树莓派基金会提供了基于ARM的Debian和Arch Linux的发行版供大众下载。还计划提供支持Python作为主要编程语言，支持Java、BBC BASIC (通过 RISC OS 映像或者Linux的”Brandy Basic”克隆)、C 和Perl等编程语言.</p>
]]></content>
      <tags>
        <tag>技术 知识</tag>
      </tags>
  </entry>
  <entry>
    <title>SSM框架</title>
    <url>/2020/03/09/SSM/</url>
    <content><![CDATA[<p>SSM（Spring+SpringMVC+MyBatis）框架集由Spring、MyBatis两个开源框架整合而成（SpringMVC是Spring中的部分内容）。常作为数据源较简单的web项目的框架。</p>
<h3 id="SpringMVC"><a href="#SpringMVC" class="headerlink" title="SpringMVC"></a>SpringMVC</h3><p>它用于web层，相当于controller（等价于传统的servlet和struts的action），用来处理用户请求。举个例子，用户在地址栏输入http://网站域名/login，那么springmvc就会拦截到这个请求，并且调用controller层中相应的方法，（中间可能包含验证用户名和密码的业务逻辑，以及查询数据库操作，但这些都不是springmvc的职责），最终把结果返回给用户，并且返回相应的页面（当然也可以只返回json/xml等格式数据）。springmvc就是做前面和后面过程的活，与用户打交道！！</p>
<h3 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h3><p>Spring：太强大了，以至于我无法用一个词或一句话来概括它。但与我们平时开发接触最多的估计就是IOC容器，它可以装载bean（也就是我们java中的类，当然也包括service dao里面的），有了这个机制，我们就不用在每次使用这个类的时候为它初始化，很少看到关键字new。另外spring的aop，事务管理等等都是我们经常用到的。</p>
<h3 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h3><p>MyBatis：如果你问我它跟鼎鼎大名的Hibernate有什么区别？我只想说，他更符合我的需求。第一，它能自由控制sql，这会让有数据库经验的人（当然不是说我啦捂脸）编写的代码能搞提升数据库访问的效率。第二，它可以使用xml的方式来组织管理我们的sql，因为一般程序出错很多情况下是sql出错，别人接手代码后能快速找到出错地方，甚至可以优化原来写的sql。</p>
<p>pom.xml</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ &lt;project xmlns=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> xmlns:xsi=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">	xsi:schemaLocation=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"</span>&gt;</span><br><span class="line">	&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">	&lt;groupId&gt;com.soecode.ssm&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;ssm&lt;/artifactId&gt;</span><br><span class="line">	&lt;packaging&gt;war&lt;/packaging&gt;</span><br><span class="line">	&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">	&lt;name&gt;ssm Maven Webapp&lt;/name&gt;</span><br><span class="line">	&lt;url&gt;http://github.com/liyifeng1994/ssm&lt;/url&gt;</span><br><span class="line">	&lt;dependencies&gt;</span><br><span class="line">		&lt;!-- 单元测试 --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.11&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- 1.日志 --&gt;</span><br><span class="line">		&lt;!-- 实现slf4j接口并整合 --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;logback-classic&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;1.1.1&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- 2.数据库 --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;5.1.37&lt;/version&gt;</span><br><span class="line">			&lt;scope&gt;runtime&lt;/scope&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;c3p0&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;c3p0&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;0.9.1.2&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- DAO: MyBatis --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.mybatis&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;mybatis&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;3.3.0&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.mybatis&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;1.2.3&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- 3.Servlet web --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;taglibs&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;standard&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;1.1.2&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;jstl&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;jstl&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;1.2&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;2.5.4&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;javax.servlet&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;3.1.0&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- 4.Spring --&gt;</span><br><span class="line">		&lt;!-- 1)Spring核心 --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-core&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-beans&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-context&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;!-- 2)Spring DAO层 --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-tx&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;!-- 3)Spring web --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-web&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;!-- 4)Spring <span class="built_in">test</span> --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spring-test&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;4.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- redis客户端:Jedis --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;redis.clients&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;jedis&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;2.7.3&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;protostuff-core&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;1.0.8&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;1.0.8&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- Map工具类 --&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;commons-collections&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;commons-collections&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;3.2&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">	&lt;/dependencies&gt;</span><br><span class="line">	&lt;build&gt;</span><br><span class="line">		&lt;finalName&gt;ssm&lt;/finalName&gt;</span><br><span class="line">	&lt;/build&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>学习  技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/03/08/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Hello-Hexo"><a href="#Hello-Hexo" class="headerlink" title="Hello Hexo"></a>Hello Hexo</h2><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
