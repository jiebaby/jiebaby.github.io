
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Machine Learning - 卡布诺奇——喵喵喵</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Jay,"> 
    <meta name="description" content="机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的,"> 
    <meta name="author" content="Jaybao"> 
    <link rel="alternative" href="atom.xml" title="卡布诺奇——喵喵喵" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
<link rel="stylesheet" href="/css/diaspora.css">

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">卡布诺奇——喵喵喵</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="icon-home image-icon" href="javascript:;" data-url="https://jiebaby.github.io"></a>
    <div title="播放/暂停" class="icon-play"></div>
    <h3 class="subtitle">Machine Learning</h3>
    <div class="social">
        <!--<div class="like-icon">-->
            <!--<a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
        <!--</div>-->
        <div>
            <div class="share">
                <a title="获取二维码" class="icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">Machine Learning</h1>
        <div class="stuff">
            <span>三月 10, 2020</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/%E7%A7%91%E6%8A%80-%E6%8A%80%E6%9C%AF-%E5%AD%A6%E4%B9%A0/" rel="tag">科技 技术 学习</a></li></ul>


        </div>
        <div class="content markdown">
            <p>机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。<br>它是人工智能的核心，是使计算机具有智能的根本途径。</p>
<p>机器学习是一门多学科交叉专业，涵盖概率论知识，统计学知识，近似理论知识和复杂算法知识，使用计算机作为工具并致力于真实实时的模拟人类学习方式， 并将现有内容进行知识结构划分来有效提高学习效率。 [1]<br>机器学习有下面几种定义：<br>(1) 机器学习是一门人工智能的科学,该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。<br>(2) 机器学习是对能通过经验自动改进的计算机算法的研究。<br>(3) 机器学习是用数据或以往的经验,以此优化计算机程序的性能标准</p>
<h3 id="决策树-decision-tree-是一种基本的分类与回归方法"><a href="#决策树-decision-tree-是一种基本的分类与回归方法" class="headerlink" title="决策树(decision tree)是一种基本的分类与回归方法"></a>决策树(decision tree)是一种基本的分类与回归方法</h3><p>决策树算法的核心在于决策树的构建，每次选择让整体数据香农熵（描述数据的混乱程度）减小最多的特征，使用其特征值对数据进行划分，每次消耗一个特征，不断迭代分类，直到所有特征消耗完（选择剩下数据中出现次数最多的类别作为这堆数据的类别），或剩下的数据全为同一类别，不必继续划分，至此决策树构建完成，之后我们依照这颗决策树对新进数据进行分类。</p>
<h3 id="结点和模块的概念"><a href="#结点和模块的概念" class="headerlink" title="结点和模块的概念"></a>结点和模块的概念</h3><p> 一个决策树，长方形代表判断模块(decision block)，椭圆形成代表终止模块(terminating block)，表示已经得出结论，可以终止运行。从判断模块引出的左右箭头称作为分支(branch)，它可以达到另一个判断模块或者终止模块。我们还可以这样理解，分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示一个类。如图所示的决策树，长方形和椭圆形都是结点。长方形的结点属于内部结点，椭圆形的结点属于叶结点，从结点引出的左右箭头就是有向边。而最上面的结点就是决策树的根结点(root node)。</p>
<h3 id="使用决策树做预测需要的过程"><a href="#使用决策树做预测需要的过程" class="headerlink" title="使用决策树做预测需要的过程"></a>使用决策树做预测需要的过程</h3><p>收集数据：可以使用任何方法。比如想构建一个相亲系统，我们可以从媒婆那里，或者通过参访相亲对象获取数据。根据他们考虑的因素和最终的选择结果，就可以得到一些供我们利用的数据了。<br>准备数据：收集完的数据，我们要进行整理，将这些所有收集的信息按照一定规则整理出来，并排版，方便我们进行后续处理。<br>分析数据：可以使用任何方法，决策树构造完成之后，我们可以检查决策树图形是否符合预期。<br>训练算法：这个过程也就是构造决策树，同样也可以说是决策树学习，就是构造一个决策树的数据结构。<br>测试算法：使用经验树计算错误率。当错误率达到了可接收范围，这个决策树就可以投放使用了。<br>使用算法：此步骤可以使用适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。</p>
<h3 id="编写代码计算经验熵"><a href="#编写代码计算经验熵" class="headerlink" title="编写代码计算经验熵"></a>编写代码计算经验熵</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line">from math import <span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:创建测试数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-07-20</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def createDataSet():</span><br><span class="line">    dataSet = [[0, 0, 0, 0, <span class="string">'no'</span>],         <span class="comment">#数据集</span></span><br><span class="line">            [0, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [0, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 1, 1, 0, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [1, 1, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 0, 0, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'年龄'</span>, <span class="string">'有工作'</span>, <span class="string">'有自己的房子'</span>, <span class="string">'信贷情况'</span>]        <span class="comment">#分类属性</span></span><br><span class="line">    <span class="built_in">return</span> dataSet, labels                <span class="comment">#返回数据集和分类属性</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:计算给定数据集的经验熵(香农熵)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵(香农熵)</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def calcShannonEnt(dataSet):</span><br><span class="line">    numEntires = len(dataSet)                        <span class="comment">#返回数据集的行数</span></span><br><span class="line">    labelCounts = &#123;&#125;                                <span class="comment">#保存每个标签(Label)出现次数的字典</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:                            <span class="comment">#对每组特征向量进行统计</span></span><br><span class="line">        currentLabel = featVec[-1]                    <span class="comment">#提取标签(Label)信息</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel not <span class="keyword">in</span> labelCounts.keys():    <span class="comment">#如果标签(Label)没有放入统计次数的字典,添加进去</span></span><br><span class="line">            labelCounts[currentLabel] = 0</span><br><span class="line">        labelCounts[currentLabel] += 1                <span class="comment">#Label计数</span></span><br><span class="line">    shannonEnt = 0.0                                <span class="comment">#经验熵(香农熵)</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:                            <span class="comment">#计算香农熵</span></span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numEntires    <span class="comment">#选择该标签(Label)的概率</span></span><br><span class="line">        shannonEnt -= prob * <span class="built_in">log</span>(prob, 2)            <span class="comment">#利用公式计算</span></span><br><span class="line">    <span class="built_in">return</span> shannonEnt                                <span class="comment">#返回经验熵(香农熵)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dataSet, features = createDataSet()</span><br><span class="line">    <span class="built_in">print</span>(dataSet)</span><br><span class="line">    <span class="built_in">print</span>(calcShannonEnt(dataSet))</span><br></pre></td></tr></table></figure>


<h3 id="编写代码计算信息增益"><a href="#编写代码计算信息增益" class="headerlink" title="编写代码计算信息增益"></a>编写代码计算信息增益</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$#</span> -*- coding: UTF-8 -*-</span><br><span class="line">from math import <span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:计算给定数据集的经验熵(香农熵)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    shannonEnt - 经验熵(香农熵)</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-03-29</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def calcShannonEnt(dataSet):</span><br><span class="line">    numEntires = len(dataSet)                        <span class="comment">#返回数据集的行数</span></span><br><span class="line">    labelCounts = &#123;&#125;                                <span class="comment">#保存每个标签(Label)出现次数的字典</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:                            <span class="comment">#对每组特征向量进行统计</span></span><br><span class="line">        currentLabel = featVec[-1]                    <span class="comment">#提取标签(Label)信息</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel not <span class="keyword">in</span> labelCounts.keys():    <span class="comment">#如果标签(Label)没有放入统计次数的字典,添加进去</span></span><br><span class="line">            labelCounts[currentLabel] = 0</span><br><span class="line">        labelCounts[currentLabel] += 1                <span class="comment">#Label计数</span></span><br><span class="line">    shannonEnt = 0.0                                <span class="comment">#经验熵(香农熵)</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:                            <span class="comment">#计算香农熵</span></span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numEntires    <span class="comment">#选择该标签(Label)的概率</span></span><br><span class="line">        shannonEnt -= prob * <span class="built_in">log</span>(prob, 2)            <span class="comment">#利用公式计算</span></span><br><span class="line">    <span class="built_in">return</span> shannonEnt                                <span class="comment">#返回经验熵(香农熵)</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:创建测试数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">    labels - 分类属性</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-07-20</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def createDataSet():</span><br><span class="line">    dataSet = [[0, 0, 0, 0, <span class="string">'no'</span>],                        <span class="comment">#数据集</span></span><br><span class="line">            [0, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [0, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 1, 1, 0, <span class="string">'yes'</span>],</span><br><span class="line">            [0, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 0, <span class="string">'no'</span>],</span><br><span class="line">            [1, 0, 0, 1, <span class="string">'no'</span>],</span><br><span class="line">            [1, 1, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [1, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 1, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 1, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 1, 0, 2, <span class="string">'yes'</span>],</span><br><span class="line">            [2, 0, 0, 0, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'年龄'</span>, <span class="string">'有工作'</span>, <span class="string">'有自己的房子'</span>, <span class="string">'信贷情况'</span>]        <span class="comment">#分类属性</span></span><br><span class="line">    <span class="built_in">return</span> dataSet, labels                             <span class="comment">#返回数据集和分类属性</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:按照给定特征划分数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 待划分的数据集</span></span><br><span class="line"><span class="string">    axis - 划分数据集的特征</span></span><br><span class="line"><span class="string">    value - 需要返回的特征的值</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    无</span></span><br><span class="line"><span class="string">Author:</span></span><br><span class="line"><span class="string">    Jack Cui</span></span><br><span class="line"><span class="string">Modify:</span></span><br><span class="line"><span class="string">    2017-03-30</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def splitDataSet(dataSet, axis, value):</span><br><span class="line">    retDataSet = []                                        <span class="comment">#创建返回的数据集列表</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:                             <span class="comment">#遍历数据集</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:</span><br><span class="line">            reducedFeatVec = featVec[:axis]                <span class="comment">#去掉axis特征</span></span><br><span class="line">            reducedFeatVec.extend(featVec[axis+1:])     <span class="comment">#将符合条件的添加到返回的数据集</span></span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="built_in">return</span> retDataSet                                      <span class="comment">#返回划分后的数据集</span></span><br><span class="line"></span><br><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">函数说明:选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Parameters:</span></span><br><span class="line"><span class="string">    dataSet - 数据集</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    bestFeature - 信息增益最大的(最优)特征的索引值</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">def chooseBestFeatureToSplit(dataSet):</span><br><span class="line">    numFeatures = len(dataSet[0]) - 1                    <span class="comment">#特征数量</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)                 <span class="comment">#计算数据集的香农熵</span></span><br><span class="line">    bestInfoGain = 0.0                                  <span class="comment">#信息增益</span></span><br><span class="line">    bestFeature = -1                                    <span class="comment">#最优特征的索引值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):                         <span class="comment">#遍历所有特征</span></span><br><span class="line">        <span class="comment">#获取dataSet的第i个所有特征</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)                         <span class="comment">#创建set集合&#123;&#125;,元素不可重复</span></span><br><span class="line">        newEntropy = 0.0                                  <span class="comment">#经验条件熵</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:                         <span class="comment">#计算信息增益</span></span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)         <span class="comment">#subDataSet划分后的子集</span></span><br><span class="line">            prob = len(subDataSet) / <span class="built_in">float</span>(len(dataSet))           <span class="comment">#计算子集的概率</span></span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)     <span class="comment">#根据公式计算经验条件熵</span></span><br><span class="line">        infoGain = baseEntropy - newEntropy                     <span class="comment">#信息增益</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"第%d个特征的增益为%.3f"</span> % (i, infoGain))            <span class="comment">#打印每个特征的信息增益</span></span><br><span class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):                             <span class="comment">#计算信息增益</span></span><br><span class="line">            bestInfoGain = infoGain                             <span class="comment">#更新信息增益，找到最大的信息增益</span></span><br><span class="line">            bestFeature = i                                     <span class="comment">#记录信息增益最大的特征的索引值</span></span><br><span class="line">    <span class="built_in">return</span> bestFeature                                             <span class="comment">#返回信息增益最大的特征的索引值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dataSet, features = createDataSet()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"最优特征索引值:"</span> + str(chooseBestFeatureToSplit(dataSet)))</span><br></pre></td></tr></table></figure>
            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="true">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='https://sharefs.yun.kugou.com/202003102118/073e21158279fe183e73394726d39a7a/G005/M00/1D/0D/RQ0DAFTANc6ANbjEAFKtpg_92Jk159.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='https://sharefs.yun.kugou.com/202003102122/886095c9b347678d9ca49a4b1507c1cc/G068/M04/0F/19/hA0DAFdE7h6AGZJPAEO0vcgc6pM218.mp3'></li>
                        
                    
                        
                            <li title='2' data-url='https://sharefs.yun.kugou.com/202003102125/3069e648539f289a705d829d2eb9bca5/G174/M05/07/11/TocBAF34lMeAb0TFADDZmjp3pFs625.mp3'></li>
                        
                    
                        
                            <li title='3' data-url='https://sharefs.yun.kugou.com/202003102142/2170c75f9dbddfce8dfb7562877132ab/G098/M00/16/15/QpQEAFvC5bKAN4iKADMKhyZT59g629.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
        data-ae='true'
        data-ci='3b039840b4dac5ef6e94'
        data-cs='2ad0e196350c4c61925649f62604989d70cc1b16'
        data-r='jiebaby.github.io'
        data-o='jiebaby'
        data-a='jiebaby'
        data-d='true'
    >查看评论</div>


    </div>
    
        <div class='side'>
            <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#决策树-decision-tree-是一种基本的分类与回归方法"><span class="toc-number">1.</span> <span class="toc-text">决策树(decision tree)是一种基本的分类与回归方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结点和模块的概念"><span class="toc-number">2.</span> <span class="toc-text">结点和模块的概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用决策树做预测需要的过程"><span class="toc-number">3.</span> <span class="toc-text">使用决策树做预测需要的过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写代码计算经验熵"><span class="toc-number">4.</span> <span class="toc-text">编写代码计算经验熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写代码计算信息增益"><span class="toc-number">5.</span> <span class="toc-text">编写代码计算信息增益</span></a></li></ol>
        </div>
    
</div>


    </div>
</div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"search":null,"path":"search.xml","field":"post","format":"html","limit":10000});</script></body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>





</html>
